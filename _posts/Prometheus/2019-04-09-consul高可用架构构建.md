---
layout: post
title:  "consul高可用架构构建"
categories: "prometheus"
tags: "prometheus consul"
author: "songzhx"
date:   2019-04-09 11:00:00
---



## 1. consul 基本原理

**为什么使用服务发现** 

防止硬编码、容灾、水平扩缩容、提高运维效率等等，只要你想使用服务发现总能找到合适的理由。

一般的说法是因为使用微服务架构。传统的单体架构不够灵活不能很好的适应变化，从而向微服务架构进行转换，而伴随着大量服务的出现，管理运维十分不便，于是开始搞一些自动化的策略，服务发现应运而生。所以如果需要使用服务发现，你应该有一些对服务治理的痛点。

但是引入服务发现就可能引入一些技术栈，增加系统总体的复杂度，如果你只有很少的几个服务，比如10个以下，并且业务不怎么变化，吞吐量预计也很稳定，可能就没有必要使用服务发现。



**Consul内部原理** 

下面这张图来源于Consul官网，很好的解释了Consul的工作原理，先大致看一下。

![img](https://tva1.sinaimg.cn/large/006y8mN6gy1g6fczk0xnuj30i20iq3zj.jpg)

首先Consul支持多数据中心，在上图中有两个DataCenter，他们通过Internet互联，同时请注意为了提高通信效率，只有Server节点才加入跨数据中心的通信。

在单个数据中心中，Consul分为Client和Server两种节点（所有的节点也被称为Agent），Server节点保存数据，Client负责健康检查及转发数据请求到Server；Server节点有一个Leader和多个Follower，Leader节点会将数据同步到Follower，Server的数量推荐是3个或者5个，在Leader挂掉的时候会启动选举机制产生一个新的Leader。

集群内的Consul节点通过gossip协议（流言协议）维护成员关系，也就是说某个节点了解集群内现在还有哪些节点，这些节点是Client还是Server。单个数据中心的流言协议同时使用TCP和UDP通信，并且都使用8301端口。跨数据中心的流言协议也同时使用TCP和UDP通信，端口使用8302。

集群内数据的读写请求既可以直接发到Server，也可以通过Client使用RPC转发到Server，请求最终会到达Leader节点，在允许数据轻微陈旧的情况下，读请求也可以在普通的Server节点完成，集群内数据的读写和复制都是通过TCP的8300端口完成。



**Consul服务发现原理** 

下面这张图是自己画的，基本描述了服务发现的完整流程，先大致看一下。

![img](https://tva1.sinaimg.cn/large/006y8mN6gy1g6fczkmux1j30id0c0jsu.jpg)

首先需要有一个正常的Consul集群，有Server，有Leader。这里在服务器Server1、Server2、Server3上分别部署了Consul Server，假设他们选举了Server2上的Consul Server节点为Leader。这些服务器上最好只部署Consul程序，以尽量维护Consul Server的稳定。

然后在服务器Server4和Server5上通过Consul Client分别注册Service A、B、C，这里每个Service分别部署在了两个服务器上，这样可以避免Service的单点问题。服务注册到Consul可以通过HTTP API（8500端口）的方式，也可以通过Consul配置文件的方式。Consul Client可以认为是无状态的，它将注册信息通过RPC转发到Consul Server，服务信息保存在Server的各个节点中，并且通过Raft实现了强一致性。

最后在服务器Server6中Program D需要访问Service B，这时候Program D首先访问本机Consul Client提供的HTTP API，本机Client会将请求转发到Consul Server，Consul Server查询到Service B当前的信息返回，最终Program D拿到了Service B的所有部署的IP和端口，然后就可以选择Service B的其中一个部署并向其发起请求了。如果服务发现采用的是DNS方式，则Program D中直接使用Service B的服务发现域名，[域名解析](https://cloud.tencent.com/product/cns)请求首先到达本机DNS代理，然后转发到本机Consul Client，本机Client会将请求转发到Consul Server，Consul Server查询到Service B当前的信息返回，最终Program D拿到了Service B的某个部署的IP和端口。







## 2.构建过程



| 主机IP        | 角色           |
| ------------- | -------------- |
| 192.168.78.12 | server、client |
| 192.168.78.13 | server、client |
| 192.168.78.14 | server、client |

master启动

```bash
nohup /home/op/consul_1.4/consul agent -server -bootstrap-expect 2 -data-dir /home/op/consul_1.4/data/consul/ -node=s1 -bind=10.142.78.12  -rejoin  -join 10.142.78.12  -client 0.0.0.0 -ui >
>/dev/null 2>&1 &
```



fllower启动

```bash
nohup /home/op/consul_1.4/consul agent -server -bootstrap-expect 2 -data-dir /home/op/consul_1.4/data/consul/ -node=s1 -bind=10.142.78.13  -rejoin  -join 10.142.78.12  -client 0.0.0.0  >
>/dev/null 2>&1 &
```



- server ： 定义agent运行在server模式，如果是client模式则不需要添加这个参数
- bootstrap-expect ：datacenter中期望提供的server节点数目，当该值提供的时候，consul一直等到达到指定sever数目的时候才会引导（启动）整个集群，为了测试演示，我们这里使用1
- bind：该地址用来在集群内部的通讯，集群内的所有节点到地址都必须是可达的，默认是0.0.0.0
- node：节点在集群中的名称，在一个集群中必须是唯一的，默认是该节点的主机名
- rejoin：使consul忽略先前的离开，在agent再次启动后仍旧尝试加入集群中。也就是说如果不加入这个参数，当前节点一旦退出，下次重启后是不会自动加入到集群中去的，除非是手动触发 `consul join xxxx` ，所以为了降低重启后对本身服务的影响，这里统一使用 -rejoin参数。
- config-dir：配置文件目录，里面文件统一规定是以.json结尾才会被自动加载并读取服务注册信息的
- client：consul服务侦听地址，处于client mode的Consul agent节点比较简单，无状态，仅仅负责将请求转发给Server agent节点



查看成员：

```bash
[op@NM-304-HW-XH628V3-BIGDATA-084 consul_1.4]$ ssh 10.142.78.14 ~/consul_1.4/consul members
Node  Address            Status  Type    Build  Protocol  DC   Segment
s1    10.142.78.12:8301  alive   server  1.4.4  2         dc1  <all>
s2    10.142.78.13:8301  alive   server  1.4.4  2         dc1  <all>
s3    10.142.78.14:8301  alive   server  1.4.4  2         dc1  <all>

```





可以通过http服务端口注册服务

```
curl -XPUT  --data @payload.json  http://10.142.78.12:8500/v1/agent/service/register

payload.json
   {
   
       "ID": "test-export",
       "Name": "export-78.12",
       "Service": "export-78.12",
       "Tags": [
         "exporter",
         "v1"
       ],
      "Address": "10.142.78.22",
      "Meta": {
          "redis_version": "test"
      },
      "Port": 9100,
      "checks": [
          {
              "http": "http://10.142.78.22:9100/metrics",
              "interval": "15s"
          }
      ]
  }

```



![image-20190410110651384](https://ws3.sinaimg.cn/large/006tNc79gy1g1xd0luzcuj326k0rqn2h.jpg)



参考： 

<https://cloud.tencent.com/developer/article/1368802>

<https://lihaoquan.me/2018/5/31/consul-in-action.html>

