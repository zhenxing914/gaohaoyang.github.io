## 1. 小文件元数据
1. 目录、文件、block都对应元数据
2. 每个元数据大约200B



## 2. 小文件给hadoop带来的瓶颈
1. 磁盘IO问题（多个文件读取开销比单个文件开销大）
2. 一个文件一个map task启动
3. 资源有限 ，namenode中存放小文件元数据，数据量太大会撑爆内存。

