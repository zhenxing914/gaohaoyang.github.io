---
layout: post
title:  "1.统计学习方法概率"
categories: "MachineLearning"
tags: "MachineLearning"
author: "songzhx"
date:   2019-11-14 15:15:00

---

## 1.统计学习方法



## 2.监督学习



### 2.1基本概念



### 2.2问题的形式化



## 3.统计学习三要素

### 3.1模型

### 3.2策略

按照什么样的准则学习或选择最优的模型。

损失函数度量模型一次预测的好坏，风险函数度量平均意义下模型预测的好坏。

**1.损失函数和风险函数**

常用的学习损失函数有以下几种：

<img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g94jqzcdnbj30v807e76j.jpg" alt="image-20191114153939147" style="zoom:50%;" />

<img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g94jr2ziksj30v806i0uy.jpg" alt="image-20191114154001745" style="zoom:50%;" />

​		损失函数值越小，模型就越好。

<img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g94jr5qkhmj30um04cmz7.jpg" alt="image-20191114162448266" style="zoom:50%;" />

<img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g94jr98m2wj30um082ju6.jpg" alt="image-20191114162505813" style="zoom:50%;" />

​		由于现实中训练样本数目有限，甚至很小，所以用经验风险评估期望风险并不理想，要对经验风险进行一定的矫正。这就是监督学习的两个基本策略：经验风险最小化和结构风险最小化。





**2.经验风险最小化与结构风险最小化**

​		当样本容量足够大时，经验风险最小化能保证有很好的学习小果果，在现实中广泛采用。比如，极大似然估计就是经验风险最小化的一个例子。

​		结构风险最小化是为了防止过拟合而提出来的策略。结构风险最小化等价于正则化。





**3.3.算法**

​		统计学习基于训练数据集，根据学习策略，从假设空间中选择最优模型，最后需要考虑用什么样的计算方法求解最优模型。



## 4.模型评估与模型选择

### 4.1训练误差与测试误差

​		通常将学习方法对未知数据的预测能力成为泛化能力。

### 4.2 过拟合与模型选择

<img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g94jrdcopbj30v60fomzu.jpg" alt="image-20191114170039403" style="zoom:50%;" />

​		当模型的复杂度增大时，训练误差会逐渐减小并趋向于0；而测试误差会先减小，达到最小值后又增大。当选择的模型复杂度过大时，过拟合现象就会发生。



## 5.正则化与交叉验证

### 5.1 正则化

​		模型选择的典型方法是正则化。正则化是结构风险最小化策略的实现，是在经验风险上加一个正则化项或惩罚项。



​		第1项的经验风险较小的模型可能较复杂（有多个非零参数），正则化的作用是选择经验风险与模型复杂度同时较小的模型。



### 5.2 交叉验证

​		另一种常用的模型选择方法是交叉验证。

1.简单交叉验证



2.s折交叉验证



3.留一交叉验证



## 6.泛化能力

### 6.1 泛化误差

​		学习方法的泛化能力是指由该方法学习到的模型对未知数据的预测能力。

​		泛化误差反映了学习方法的泛化能力，如果一种方法学习的模型比另一种方法学习的模型具有更小的泛化误差，那么这种方法就更有效。

### 6.2 泛化误差上界

<img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g94jrgye3rj30wk06q0uo.jpg" alt="image-20191114180354694" style="zoom:50%;" />

​		  <img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g94jrjff8qj30wk07ugor.jpg" alt="image-20191114180424344" style="zoom:50%;" />	

​	训练误差效的模型，其泛化误差也会小。



## 7.生成模型与判别模型

​	监督学习方法分为生成方法和判别方法。所学到的模型分别为生成模型和判别模型。



**生成方法的特点：**

​	生成方法可以还原出联合概率分布P(X,Y),而判别方法则不能。生成方法的学习收敛速度更快，即当样本容量增加的时候，学到的模型可以更快地收敛于真是模型。当存在隐变量时，仍可以用生成方法学习，此时判别方法就不能。

**判别方法的特点：**

​	判别方法直接学习的是条件概率P(Y|X)或决策函数f(X)，直接面对预测，往往学习的准确率更高。由于直接学习P(Y|X)或P(X),可以对数据进行各种程度上的抽象、定义特征并使用特征，因此可以简化学习问题。



## 8.分类问题

对于二分类问题常用的评价指标是准确率与召回率。通常以关注的类为正类，其他类为负类，分类器在测试数据集上的预测或正确或不正确，4种情况出现的总数分别为：

<img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g94jrnklu2j30su0jmq77.jpg" alt="image-20191115105502574" style="zoom:50%;" />

准确率和召回率都高时，F1值也会很高。



##  9.标注问题

​	评价标注模型的指标和评价分类模型的指标一样，常用的有标注准确率、精确率和召回率。其定义与分类模型相同。

​	标注常用的统计学习方法有：隐马尔科夫模型、条件随机场。



## 10.回归问题

​	回归模型正是表示从输入变量到输出变量之间的映射的函数。回归问题的学习等价于函数拟合。

​	回归学习按照输入变量的个数，分为一元回归和多元回归；按照输入变量和输出变量之间关系的类型即模型的类型，分为线性回归和非线性回归。

​		回归学习最常用的损失函数是平方损失函数，在此情况下，回归问题可以由著名的最小二乘法求解。















