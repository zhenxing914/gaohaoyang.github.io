
## 1. reduceByKey和groupByKey

<img src="https://tva1.sinaimg.cn/large/00831rSTgy1gd6il9vlprj30v20iqdpl.jpg" alt="image-20200225192832166" style="zoom:50%;" />

```scala
val conf = new SparkConf().setAppName("GroupAndReduce").setMaster("local")
val sc = new SparkContext(conf)
val words = Array("one", "two", "two", "three", "three", "three")
val wordsRDD = sc.parallelize(words).map(word => (word, 1))
val wordsCountWithReduce = wordsRDD.
      reduceByKey(_ + _).
      collect().
      foreach(println)
val wordsCountWithGroup = wordsRDD.
      groupByKey().
      map(w => (w._1, w._2.sum)).
      collect().
      foreach(println)
```

函数的具体实现
```scala
  def reduceByKey(partitioner: Partitioner, func: (V, V) => V): RDD[(K, V)] = self.withScope {
    combineByKeyWithClassTag[V]((v: V) => v, func, func, partitioner)
  }
```

```scala
  /**
  * Note: As currently implemented, groupByKey must be able to hold all the key-value pairs for any
   * key in memory. If a key has too many values, it can result in an [[OutOfMemoryError]].
   */
  def groupByKey(partitioner: Partitioner): RDD[(K, Iterable[V])] = self.withScope {
    // groupByKey shouldn't use map side combine because map side combine does not
    // reduce the amount of data shuffled and requires all map side data be inserted
    // into a hash table, leading to more objects in the old gen.
    val createCombiner = (v: V) => CompactBuffer(v)
    val mergeValue = (buf: CompactBuffer[V], v: V) => buf += v
    val mergeCombiners = (c1: CompactBuffer[V], c2: CompactBuffer[V]) => c1 ++= c2
    val bufs = combineByKeyWithClassTag[CompactBuffer[V]](
      createCombiner, mergeValue, mergeCombiners, partitioner, mapSideCombine = false)
    bufs.asInstanceOf[RDD[(K, Iterable[V])]]
  }
```



## 2. FoldByKey 与reduceByKey

虽然reduceByKey和foldByKey都是聚合的但是foldByKey多了一个初始值，通过代码就能看出来:

```java
b.reduceByKey(_ + _).collect			//reduceByKey
b.foldByKey("")(_ + _).collect		//foldByKey 
```

foldByKey是柯里化函数。

### 1. 对空的RDD应用

```scala
//创建一个空的RDD
val emptyRdd = sc.emptyRDD[Int]

//对空的RDD进行reduce会报如下错
//java.lang.UnsupportedOperationException: empty collection
//  at org.apache.spark.rdd.RDD$$anonfun$reduce$1$$anonfun$apply$36.apply(RDD.scala:1027)
emptyRdd.reduce(_ + _)

//对空的RDD进行fold则不会，而是返回0
emptyRdd.fold(0)(_ + _) // res1: Int = 0
```



### 2. 产生临时对象

```scala
//创建一个RDD，RDD的类型为ArrayBuffer
val testRdds = sc.parallelize(Seq(ArrayBuffer(0, 1, 3), ArrayBuffer(2, 4, 5)))

//对testRdds进行reduce，如下：
//会产生很多的中间临时对象 因为ArrayBuffer ++ ArrayBuffer会创建一个新的ArrayBuffer对象
testRdds.reduce(_ ++ _)

//对testRdds进行fold，如下：
// ArrayBuffer只初始化一次，每次都是将ArrayBuffer append到之前的ArrayBuffer中，不会产生中间临时对象
testRdds.fold(ArrayBuffer.empty[Int])((buff, elem) => buff ++= elem)
```



## 3. map和mapPartition（transform）

场景：连接数据库写入数据至表中。

1. map ：有多少个元素就会创建多少个connection。
2. mapPartition ：按照分区数创建connection。
   1. 缺点： 一个partion数据量太大，会出现内存不够情况。
   2. 解决方案：增加partition个数。

<img src="https://tva1.sinaimg.cn/large/00831rSTgy1gd6il44hlrj30fs0c8goe.jpg" alt="image-20200225192653781" style="zoom:50%;" />



## 4. foreach和foreachPartition

1. 是action，写数据库更好
2. 和map、mapPartition用法一

<img src="https://tva1.sinaimg.cn/large/00831rSTgy1gd6il09x3ej30fs04emyp.jpg" alt="image-20200225192813735" style="zoom:50%;" />



## 5. partitonBy和repartition

repartition 和 partitionBy 都是对数据进行重新分区，默认都是使用 **HashPartitioner**，区别在于**partitionBy 只能用于 PairRDD**，但是当它们同时都用于 PairRDD时，结果却不一样。

![img](https://tva1.sinaimg.cn/large/00831rSTgy1gd6inndv40j30pz05y3z2.jpg)

其实 partitionBy 的结果才是我们所预期的。

​		**repartition即使是RairRDD也不会使用自己的key，repartition 其实使用了一个随机生成的数来当做 Key**，而不是使用原来的 Key。



##  6. coalesce和repartition

1. repartition将partition调大
2. coalesce 将partition调小



##  7. cache和persist

<img src="https://tva1.sinaimg.cn/large/00831rSTgy1gd6ikrhm1yj30j0058dhb.jpg" alt="image-20200225193007030" style="zoom: 60%;" />

## 8. persit与checkpoint区别

​		rdd.persist(StorageLevel.DISK_ONLY) 与 checkpoint 区别的是：前者虽然可以将 RDD 的 partition 持久化到磁盘，但该 partition 由 blockManager 管理。一旦 driver program 执行结束，也就是 executor 所在进程 CoarseGrainedExecutorBackend stop，blockManager 也会 stop，**被 cache 到磁盘上的 RDD 也会被清空**（整个 blockManager 使用的 local 文件夹被删除）。而 checkpoint 将 RDD 持久化到 HDFS 或本地文件夹，如果不被手动 remove 掉（ 话说怎么 remove checkpoint 过的 RDD？ ），是一直存在的，也就是说可以被下一个 driver program 使用，而 cached RDD 不能被其他 dirver program 使用。

​		因为checkpoint是需要把 job 重新从头算一遍， 最好先cache一下， checkpoint就可以直接保存缓存中的 RDD 了， 就不需要重头计算一遍了， 对性能有极大的提升。

## 9. textfile和wholeTextFile

<img src="https://tva1.sinaimg.cn/large/00831rSTgy1gcoyvjdczjj30vc0g1gpl.jpg" alt="img" style="zoom:67%;" />

<img src="https://tva1.sinaimg.cn/large/00831rSTgy1gcoyvvy7nsj30t40ho0wj.jpg" alt="img" style="zoom:67%;" />

**1. sc.textFiles(path) :**

**能将path 里的所有文件内容读出，以文件中的每一行作为一条记录的方式，**文件的每一行 相当于 List中以 “,”号 隔开的一个元素，因此可以在每个partition中用for i in data的形式遍历处理Array里的数据;

**2. sc.wholeTextFiles():**
返回的是[(K1, V1), (K2, V2)...]的形式，其中K是文件路径，V是文件内容，这里我们要注意的重点是：
官方一句话：''**Each file is read as a single record**'' 这句话，每个文件作为一个记录！这说明这里的 V 将不再是 list 的方式为你将文件每行拆成一个 list的元素,而是**将整个文本的内容**以字符串的形式读进来，也就是说val = '...line1...\n...line2...\n'，这时需要你自己去拆分每行！而如果你还是用for i in val的形式来便利 val那么i得到的将是每个字符.

**3. 两种读取文件下与partition的数量关系**

- 用textFile时，**它的partition的数量是与文件夹下的文件数量（实例中用3个xxx.log文件）相关**，一个文件就是一个partition(既然3个文件就是：partition=3)。

- wholeTextFiles的**partition数量是根据用户指定或者文件大小来**（文件内的数据量少 有hdfs源码默认确定的）确定，与hdfs目录下的文件数量无关！ 所以说：**wholeTextFile通常用于读取许多小文件的需求**。




## 10. collect

1. 返回的所有数据都会放在一个数组中同时加载在Driver端内存中。
2. 容易导致OOM

<img src="/Users/song/Library/Application Support/typora-user-images/image-20200225192928774.png" alt="image-20200225192928774" style="zoom:50%;" />

## 11.updateByKey和mapWithState



## 12. parallize与makeRDD



## 13. sortBy和sortByKey区别

​	sortByKey是对pairRDD进行排序

​	sortBy是对标准RDD进行排序。





## 参考

textfile和wholeTextfile： https://www.520mwx.com/view/9778

checkpoint和persist区别：https://www.jianshu.com/p/b0a66c64bd85

