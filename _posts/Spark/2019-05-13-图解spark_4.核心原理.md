---

layout: post
title:  "图解spark_4.核心原理"
categories: "Spark"
tags: "Spark "
author: "songzhx"
date:   2019-05-17 09:47:00 
---

## 1.消息通信原理

### 1.1 spark消息通信架构

 <img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g7cwabr1o4j31200f6dme.jpg" alt="image-20190919101729197" style="zoom:50%;" />


​      

### 1.2 spark启动消息通信

​		Spark 启动过程中主要是进行Master与Worker之间的通信，其消息发送关系如图，首先由Worker节点向Master发送注册信息，然后Master处理完毕后，返回注册成功消息或失败消息，如果成功注册，则Worker定时发送心跳消息给Master。


​         <img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g7cwafuyddj30pu0kagrh.jpg" alt="image-20190919101218147" style="zoom:50%;" />


​       

### 1.3 运行时消息通信

 <img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g7cwaiktblj30us0isgng.jpg" alt="image-20190924091907102" style="zoom:50%;" />

1. RegisterApplication

2. RegisteredApplication

3. LauchExecutor

4. ExecutorStateChanged

5. RegisterExecutor

6. RegistedExecutor

7. LauchTask

8. 在TaskRuner执行任务完成时，会由向DriverEndPoint终端店点发送状态变更StatusUpdate消息，当DriverEndPoint终端店接受到该消失时，调用TaskSchedualerImpl的statusUpdate方法，根据任务执行不同的结果进行处理，处理完毕后再给该Executor分配执行任务。



## 2. 作业执行原理


### 2.1 概述
​		Spark的作业调度主要是基于RDD的一系列操作构成一个作业，然后在Executor中执行。这些操作算子主要分为**转换操作**和**行动操作**，对于转换操作的计算是lazy级别的，也就是延迟执行，只有出现了行动操作才出发了作业的提交。在Spark调度中最重要的是DAGScheduler和TaskScheduler两个调度器。
​    

​		其中DAGScheduler负责任务的逻辑调度，将作业拆分成不同阶段的具有依赖关系的任务集，而TaskScheduler则负责具体任务的调度执行。

<img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g7cwalxml2j30xo0jyqck.jpg" alt="image-20190924133923325" style="zoom:50%;" />

​	spark系统实现类图：
​     <img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g7cwap622nj31160n8k4q.jpg" alt="image-20190924134848189" style="zoom:60%;" />

  

### 2.2 作业提交


 		已经典的WordCount为例来分析提交作业的情况：

   ![image-20190924135137241](https://tva1.sinaimg.cn/large/006y8mN6gy1g7cwasdyx6j311603mac4.jpg)

​     	SparkContext的runJob方法经过几次调用后，进入DAGScheduler的runJob方法。

![image-20190924140022228](https://tva1.sinaimg.cn/large/006y8mN6gy1g7cwauqwpdj311603mwga.jpg)
![image-20190924140036772](https://tva1.sinaimg.cn/large/006y8mN6gy1g7cwaxm7tmj310y0a8tby.jpg)

  	在Spark应用程序中，会拆分多个作业，然后对多个作业之间的调度，spark目前提供了两种调度策略：一种是FIFO模式，这也是目前默认的模式；另外是FAIR模式。


​     

### 2.3 划分调度阶段

​         代码实现在DAGScheduler的handleJobSubmitted方法中根据最后一个RDD生成ResultStage开始的，具体方法从finalRDD使用getParentStages找出其依赖的祖先RDD是否存在Shuffle操作。

​		**如果没有shuffle操作**，则本次作业仅有一个resultStage，该ResultStage不存在父调度阶段；

​		**如果存在shuffle操作**，则本次作业存在一个resultStage和至少一个ShuffleMapStage,该ResultStage存在父调度阶段。

![image-20190924164646225](https://tva1.sinaimg.cn/large/006y8mN6gy1g7cwb1u7f3j310y0ggdh9.jpg)

1. 在SparkContext中提交运行时，会调用DAGScheduler的handleJobSubmitted进行处理，在该方法中会先找到最后一个RDD（即rddG），并调用getParentStages方法。

2. 在getParentStages方法判断rddG的依赖RDD树中是否存在Shuffle操作，在该例子中发现join操作为Shuffle操作，则后去进行该操作的RDD为rddB和rddF。

3. 

4. 



### 2.4 提交调度阶段

​		在DAGScheduler的handleJobSubmitted方法中，生成finalStage的同时建立起所有调度阶段的依赖关系，然后通过finalStage生成一个作业实例，在该作业实例中按照顺序提交调度阶段进行执行，在执行过程中通过监听总线获取作业、阶段执行情况。

作业提交调度阶段开始时，在submitStage方法中调用getMissingParentStages方法获取finalStage父调用阶段。

如果不存在父调用阶段，则使用submitMissingTasks方法提交执行；

如果存在父调用阶段，则把该阶段放在waitingStages列表中，同时递归调用submitStage。

通过该算法把存在父调用阶段的等待调度阶段放入列表waitingStages中，不存在父调度阶段作为作业运行的入口。

​	<img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g7cwb53fx6j30zu0niqf1.jpg" alt="image-20190925110552435" style="zoom:60%;" />

（1）在handleJobSubmitted方法中获取了该例子最后一个调度阶段ResultStage3，通过submitStage方法提交运行该调度阶段。

（2）在submitStage方法中，先创建作业实例，然后判断该调度阶段是否存在父调用阶段，由于ResultStage3有两个父调度阶段ShuffleMapStage0和ShuffleMapStage2，所以并不能立即提交调度阶段运行，把ResultStage3假如到等待执行调度阶段列表waittingStates中。

（3）

（4）

（5）



### 2.5 提交任务

​       当调度阶段提交运行后，在DAGScheduler的submitMissingTasks方法中，会根据调度阶段**Partition个数拆分对应个数任务**，这些任务组成一个任务集提交到TaskScheduler进行处理。对于ResultStage（作业中最后的调度阶段）生成ResultTask，对于ShufflleMapStage生成ShuffleMapTask。对于每一个任务集包含了对应调度阶段的所有任务，这些任务处理逻辑完全不一样，不同的是对应处理的数据，而这些数据是其对应的数据分片。

​		当TaskScheduler收到发送过来的任务集时，在submitTasks方法中构建一个TaskSetManager会放入系统的调度池中，根据系统设置的调度算法进行调度。

​		参见spark作业执行类图，sparkDeploySchedulerBackend的reviveOffers方法是继承于父类CoarseGrainedSchedulerBackend，**该方法会向DriverEndPoint终端点发送消息**，调用其makeOffers方法。在该方法中先会获取集群中可用的Executor，然后发送到TaskSchedulerImpl中进行对任务集的任务分配运行资源，最后提交到launchTasks方法中。

​		在TaskSchedulerImpl的resourceOffers方法中进行非常重要的步骤--资源分配，在分配的过程中会根据调度策略对TaskSetManager进行排序，然后依次对这些TaskSetManager按照就近原则分配资源，按照顺序为PROCESS_LOCAL、NODE_LOCAL、NO_PREF、RACK_LOCAL和ANY。

​		分配好资源的任务提交到CoarseGrainedSchedulerBackend的launchTasks方法中，在该方法中会把任务一个个发送到Worker节点上的CoarseGrainedExecutorBackend，然后通过其内部的Executor来执行任务。



### 2.6 执行任务

​		当CoarseGrainedExecuotorBackend接收到LaunchTask消息时，会调用Executor的launchTask方法进行处理。在Executor的launchTask方法中，初始化一个TaskRunner来封装任务，他用于管理任务运行时的细节，再把TaskRunner队形放入到ThreadPool中去执行。

​		对于ShuffleMapTask而言，它的计算**结果会写到BlockManager之中**，最终返回给DAGScheduler的是一个MapStatus对象。该对象中管理了ShuffleMapTask的运算结果存储到BlockManager里的相关存储信息，而不是计算结果本身。

​		对于ResultTask的runTask方法而言，它最终返回的是func函数的计算结果。



### 2.7 获取执行结果

​	对于Executor的计算结果，会根据结果的大小有不同的策略。

- （1）生成结果 （无穷 ，1G)：结果直接丢弃 

- （2）生成结果 [1GB,128MB-200KB]：会把结果以taskId为编号存入到BlockManager中，然后把该编号通过Netty发送给Driver终端点。

- （3）[128MB-200KB,0]：通过Netty直接发送到Driver终端点。

​     任务执行完毕后，TaskRunner将任务的执行结果发送给DriverEndPoint终端点。该终端点会转给TaskSchedulerImpl的statusUpdate方法进行处理。

- （1）如果类型是TaskStatus.FINISHED，那么调用TaskResultGetter的enqueueSuccessfulTask方法进行处理。
- （2）如果类型是TaskStatus.FAILED或者TaskState.KILLED或者TaskState.LOST,调用TaskResultGetter的enqueueFailedTask进行处理。

<img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g7cwba6ip8j310m0j4ac7.jpg" alt="image-20190925142938706" style="zoom:67%;" />



## 3. 调度算法

### 3.1 应用程序之间

​		ClusterManager提供了资源的分配和管理，而在独立运行模式中Master提供了资源管理调度功能。在调度过程中，Master先启动等待列表中应用程序的Driver，这些Driver尽可能分散在集群的Worker节点上，然后根据集群的内存和CPU使用情况，对等待运行的应用程序进行资源分配，在分配的应用程序只能在剩余资源中再次筛选。如果没有合适资源你的应用程序只能等待，知道其他应用程序释放。

​		在分配应用程序资源的时候，会根据worker的分配策略进行。分配算法有2种：

​		一种把应用程序运行在尽可能多的worker上，这种分配算法不仅**能够充分使用集群资源**，而且有利于数据处理的本地性。

​		另一种是应用程序运行在尽可能少的worker上，该情况适合**CPU密集型而内存使用较少**的场景。

### 3.2 作业及调度阶段之间

​		Spark应用程序提交执行时，会根据RDD依赖关系形成有向无环图DAG，然后交给DAGScheduler进行划分作业和调度阶段。这些作业之间可以没有任何依赖关系，对于多个作业之间的调度，spark目前提供了2种调度策略：**1.FIFO模式**，这也是默认模式；**2.FAIR模式**

**1. 创建调度池**

​       TaskSchedulerImpl.initalize方法中先创建**根调度池rootPool**对象，然后根据系统配置的调度模式创建调度创建器，针对两种调度策略具体实例化FIFOSchedulerBuilder或FairSchedulerBuilder，最终使用调度创建器的buildPool方法在根调度池rootPool下创建调度池。

**2 调度池加入调度内容**

​       在TaskSchedulerImpl.submitTask方法中，先把调度阶段拆分为任务集，然后把这些任务集交给管理器TaskSetManager进行管理，最后把该任务集的管理器假如到调度池中，等待分配执行。

​		在FIFO中，由于创建器的buildPools方法为空，所以在**根调度池rootPool中并没有下级调度池**。

**3 提供已排序的任务集管理器**

​		在TaskSchedulerImpl.resourceOffers方法中进行资源分配时，会从根调度池rootPool获取已经排序的任务管理器，该排序算法由两种调度策略FIFOSchedulerAlgorithm和FairSchedulingAlgorithm的comparator方法提供。



### 3.3 任务之间

**1.数据本地性**

​       数据的计算尽可能在数据所在的节点上运行，这样可以减少数据在网络上传输，毕竟移动计算比移动数据代价来的小些。

**2.延迟执行**

​       在任务分配运行节点时，先判断任务最佳运行节点是否空闲，如果该节点没有足够的资源运行该任务，在这种情况下任务会等待一定时间；如果在等待时间内该节点释放出足够的资源，则任务在该节点上运行，如果还是不足会找出次佳的节点进行运行。

在任务分配中TaskSetManager是核心对象，

1. 先在其初始化的时候使用addPendingTask方法，根据任务自身的首选位置得到pendingTaskForExecutor、pendingTasksForHost、pendingTasksWithNoPrefs和pendingTasksForRack4个列表
2. 然后根据这4个列表在computeValidLocalityLevels方法中得到该**任务集的数据本地性**，按照获取的数据本地性从高到低匹配可用的Worker节点，在匹配前使用getAllowedLocalityLevel方法得到**数据集允许的数据本地性**，比较该数据本地性和指定数据本地性优先级，取优先级高的数据本地性。
3. 最后在指定的Worker节点中判断比较获得的数据优先级是否存在需要运行的任务，如果存在则返回该任务和数据本地性进行相关信息更新处理。

> 其中maxLocalityL<- taskSet.myLocalityLeves 会调用computeValidLocalityLevels方法获取任务集的数据本地性。
>
> 其中resourceOfferSingleTaskSet方法内会调用getAllowedLocalityLevel方法得到数据集允许的数据本地性。

resourceOff代码如下：

<img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g7xprw2jbcj30u00xyh3w.jpg" alt="image-20191014143016719" style="zoom:60%;" />

​		对单个任务集的任务调度由TaskSchedulerImpl.resourceOfferSingleTaskSet方法实现，在该方法中会遍历所有Worker，先判断Worker中的CPU核数是否满足任务任性的核数，如果满足则调用resourceOffer方法对该Worker的Executor分配运行任务，分配完毕后更新任务对应任务集管理器列表、任务对应Executor列表和Executor对应机器列表，并减少该任务使用的CPU核数。

​		对指定Worker的Executor分配运行的任务调用TaskSetManager.resourceOffer方法实现。首先，在该方法中调用getAllowedLocalityLevel方法获取当前任务集允许执行的数据本地性，如果获取运行的数据本地性比指定的数据本地性优先级来的低，则使用指定的数据本地性。

​		再看看TaskSetManager.getAllowedLocalityLevel方法获取当前任务集允许执行的数据本地性实现，在该方法从上次获取到的数据本地性开始，根据优先级从高到低判断是否存在任务需要运行，如果对于其中一级数据本地性没有存在需要运行的任务，则不进行延迟等待，而是进行下一级数据本地性处理。如果存在需要运行的任务，但延迟时间超过了该数据本地性设置的延迟时间，那么也进行下一级数据本地性处理。如果不满足前面两种情况，则返回数据本地性。而判断数据本地性是否存在需要运行任务的方法是：在正在运行任务copiesRunning和成功运行任务successful两个列表中检查是否包含指定的任务，如果这两个列表中不包含，则表示该任务需要处理，反之该任务不需要处理。

<img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g7xq0hggktj30xs0u0ars.jpg" alt="image-20191014143833726" style="zoom:60%;" />



## 4. 容错及HA

### 4.1 Executor异常

<img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g7cwbevhq8j30y40mgn63.jpg" alt="image-20190926133907258" style="zoom:55%;" />



### 4.2 Worker异常

<img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g7cwbhp5hyj30y40mgth6.jpg" alt="image-20190926134113023" style="zoom:55%;" />

###4.3 Master异常

<img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g7cwbmug76j30y40mgdom.jpg" alt="image-20190926134232940" style="zoom:55%;" />

## 5.监控管理

### 5.1 UI监控

1. 实时UI监控

- masterUI

- 应用UI

  （1）作业监控页面

  （2）调度监控页面

  （3）存储监控页面

  （4）运行环境监控页面

  （5）Executor监控页面

  （6）Streaming监控页面

  

2.历史UI监控

默认情况下Spark没有打开历史UI监控功能。

- Spark应用程序完成后提交给YARN RM，然后RM将信息从RM UI写到History Server UI上。

  

### 5.2 Metrics

1.输入源介绍

2.输出方式介绍



### 5.3 REST

1.应用程序信息

2.作业信息

3.调度阶段信息

4.Executor信息

5.存储信息






