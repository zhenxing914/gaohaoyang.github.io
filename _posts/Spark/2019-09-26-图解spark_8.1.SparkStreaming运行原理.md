---

layout: post
title:  "图解spark_8.SparkStreaming"
categories: "Spark"
tags: "Spark "
author: "songzhx"
date:   2019-10-16 11:06:00 
---

## 1. SparkStreaming介绍

### 1.1 术语定义

**1.离散流（Discretized Stream）或DStream**

​		DStream定义了名为generatedRDDs离散数据流，它是以时间为键、RDD为值得哈希列表。在流数据接受过程中，源源不断地把接受到的数据放入到该列表中，而对于不需要的旧RDD从该列表中删除。

**2.DStreamGraph**

​		SparkStreaming中作业的生成和Spark核心类似，对DStream进行的各种操作让他们之间构建起依赖关系。当遇到DStream使用输出操作时，这些依赖关系以及他们之间的操作会被记录到名为DStreamGraph的对象中表示一个作业。这些作业注册到DStreamGraph并不会立即运行，而是等到Spark Streaming启动后，到达批处理时间时，才根据DStreamGraph生成作业处理该批处理时间内接受的数据。

**3.批处理间隔**

​		在SparkStreming中，数据采集是逐条进行的，而数据处理是按批进行的，因此在SparkStreaming中会先设置好批处理间隔。当超过批处理间隔的时候就会把采集到的数据汇总起来成为一批数据交给系统去处理。

**4.窗口间隔和滑动间隔**

​		对于窗口操作而言，在其窗口内部会有N个批处理数据，批处理数据的个数由窗口间隔决定，气味窗口持续的时间，在窗口操作中只有窗口间隔满足了才会触发批数据的处理。

​		除了窗口的长度，另一个参数是滑动价格，它指的是经过多长时间窗口滑动一次形成新的窗口。

<img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g817o5as5qj312u0d6dki.jpg" alt="image-20191017104759533" style="zoom:50%;" />



### 1.2 SparkStreming特点

**1.流式处理**

**2.高容错**

**3.低延迟**

**4.吞吐量高**



## 2.SparkStreaming编程模型

### 2.1. DStream的输入源

**1.基础来源**

​	多种文件系统HDFS、S3 和NFS等

**2.高级来源**

​	如Kafka和Flume



### 2.2  DStream的操作

**1.普通的转换操作**



**2.窗口转换操作**



**3.输出操作**



## 3.运行架构

### 3.1 运行架构

SparkStreaming分为Driver端和Client端，

运行在**Driver端**为StreamingContext实例，该实例中包含DStreaGraph和JobSheduler（包括ReceiverTracker和JobGenerator）等，

而**client端**包括ReceiverSupervisor和Receiver等。

流数据处理大致分为：**启动流处理引擎、接收及存储流数据、处理流数据和输出处理结果**等4个步骤。

<img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g810py146rj31140s4h3n.jpg" alt="image-20191017110541699" style="zoom:50%;" />

1. 初始化StreamingContext对象，该对象启动过程中实例化DStreamGraph和JobScheduler，其中DStreamGraph用于存放DStream以及DStrem之间的依赖关系等信息，而JobSheduler中包括ReceiverTracker和JobGenerator。在**ReceiverTracker**启动过程中，根据流数据接收器分发策略通知对应的Executor中的流数据接受管理器ReceiverSupervisor启动，再由ReceiverSuperviosr启动流数据接收器。

2. 当流数据接收器Receiver启动后，持续不断的接收实时流数据，根据传过来数据的大小进行判断，如果数据量很小，则攒成多条数据成一块，然后再进行块存储；如果数据量大，则直接进行块存储。对于这些数据Receiver直接交给ReceiverSupervisor，由其进行数据转储操作。

3. 在StreamingContext的**JobGenerator**中维护一个定时器，该定时器在批处理时间到来时会进行生成作业的操作。在该操作中进行如下操作：

​	（1）通知ReceiverTracker将接收到的数据进行提交

​	（2）要求DStreamGraph根据DStream依赖关系生成作业序列Seq

​	（3） 从第一步中ReceiverTracker获取本批次的数据的元数据.

​	（4） 把批处理时间time,作业序列Seq和本批次数据的元数据包装成JobSet，调用JobScheduler.submitJobSet()提交给JobScheduler，JobScheduler将把这些作业发送给Spark核心进行处理，由于该执行为异步，因此本步执行速度将很快。

​	（5）只要提交结束，SparkStreaming对整个系统做一个检查点。

​	4. 在Spark核心的作业对数据进行处理，处理完毕后输出到外部系统，如文件系统。由于实时流数据的数据源源不断流入，Spark会周而复始地进行数据处理，相应也会持续不断地输出结果。



### 3.2 消息通信

​		下面对StreamingConext启动流处理引擎和接收存储流数据中进行的消息通信进行详细分析。

<img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g815omdwbvj30sq0pigwi.jpg" alt="image-20191017135727279" style="zoom:50%;" />

​		具体过程如下：

（1）在启动流处理引擎过程中，JobSheduler在内部启动ReceiverTracker和ReceiverTrackerEndPoint终端点，当ReceiverTracker准备完毕后向终端点发送StartAllReceivers消息，通知其分发并启动所有流数据接收器Receiver。

（2）启动流数据接收器Receiver前，ReceiverSupervisor会向ReceiverTrackerEndPoint终端点发送RegisterReceiver注册消息，当注册成功后才继续进行流数据接收器Receiver的启动。

（3）在流数据接收器Receiver接收数据的过程中，当保存完一个数据块时，作为数据转储的管理者ReceiverSupervisor会把**数据块的元数据发送给ReceiverTrackerEndPoint终端点**,ReceiverTracker再把这些信息转发给ReceiverBlockTracker，由它负责管理收到的数据块的元信息。

（4）当SparkStreaming停止运行时，ReceiverTracker发送注销所有流数据接收器Receiver消息，ReceiverTrackerEndPoint终端点接收到该消息会调用ReceiverTracker.stop方法注销。



### 3.3 Receiver分发

<img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g817614jhcj30vm0lgqeb.jpg" alt="image-20191017144847267" style="zoom: 60%;" />

1. 先遍历ReceiverInputStream，通过其getReceiver获取需要启动的N个Receiver实例，然后把这些实例作为N份数据，在StreamingContext创建一个RDD实例，该RDD分为N个partition，每个partition对应包含一个Receiver数据。
2. 在这里我们把Receiver所进行的计算定义为func函数，该函数以Receiver实例为参数构造ReceiverSupervisorImpl实例supervisor，构造完毕后使用新线程启动该supervisor并阻塞该线程。
3. 把ReceiverTracker尽可能的按照Receiver的首选位置分发到集群并启动，启动完毕后Receiver会处于阻塞状态，持续不断的接入流数据。



### 3.4 容错性

<img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g817o14h8fj30xe0gkdp8.jpg" alt="image-20191017150600757" style="zoom:60%;" />

用户传送数据的生命周期：

1. 接收数据：接收器将数据流分成一系列小块，存储到Executor内存或磁盘中。如果启用预写日志，数据同时还写入到容错文件系统的预写日志文件中。

2. 通知StreamingContext：接收块中的元数据被发送到Driver的StreamingContext。

3. 处理数据：每批数据的间隔，流上下文使用块信息产生弹性分布数据集RDD和他们的作业Job，StreamingContext通过运行任务处理Executor内存或磁盘中的数据块来执行作业。

4. 周期性地设置检查点：为了恢复的需要，流计算周期性地设置检查点，并保存到同一个容错文件系统中另外的一组文件中。



## 4.运行原理

### 4.1 启动流处理引擎

<img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g7zzgwaf5wj31160l246l.jpg" alt="image-20191016133649972" style="zoom:60%;" />

**1.初始化StreamingContext**

​		会初始化以下几个成员变量，

DStreamGraph跟RDD的有向无环图蕾西，包含DStream之间相互依赖的有向无环图；

JobScheduler的作用是定时查看DStreamGraph，然后根据流入的数据生成作业；

StreamingTab是在sparkStreaming的作业运行时，提供对流数据处理的监控。

**2.创建InputStream**

​		在SocketInputDStream内部重写了ReceiverInputDStream中的getReceiver方法。该方法是用来生成接收器的。在getRecevier方法内部创建了一个SocketReceiver实例，并在该实例中启动线程接收数据。



**3.启动JobScheduler**

​		InputStream后，调用StreamingContext的start方法进行Spark Streaming应用程序的启动，其最重要的就是启动JobScheduler。在JobScheduler启动过程中，实例化并启动ReiceiverTracker和JobGernerator。



**4.启动JobGernerator**

​		启动JobGernerator需要判断是否是第一次运行，如果不是第一次运行需要进行上一次检查点的恢复。在该方法中初始化了定时器的开启时间，并启动DStreamGraph和定时器timer。



### 4.2 接收及存储流程

**1. 启动ReceiverTracker**

​		启动ReceiverTracker先调用ReceiverTracker.lauchReiceivers方法。该方法会向ReceiverTrackerEndPoint终端点发送分发，并启动所有流数据接收器的消息。

<img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g800ey5tslj31120p4wh5.jpg" alt="image-20191016140506265" style="zoom:60%;" />

​		分发到Executor的流数据接收器由ReiceiverTrackerEndPoint.startReceiver方法进行启动，在该方法中开启了一个ReceiverSupervisor对象来管理该流数据接收器。

​		在ReiceiverSupervisor的start方法中调用了其自身的onStart和startReceiver两个方法，在onStart方法中启动了BlockGenerator，而在startReceiver方法中完成了流数据接收器的注册和启动。



**2.启动流数据接收器并接收数据**

​		在ReceiverSupervisor.startReceiver方法进行流数据接收器的启动，先调用ReceiverSupervisorImpl的onReceiverStart方法向ReceiverTrackerEndPoint终端点发送RegisterReceiver注册消息，如果注册成功了，则调用SocketReceiver.onStart方法开始接受数据。

​				

**3.启动BlockGernerator并生成数据**

​		在ReceiverSupervisorImpl.onStart方法中调用BlockGenerator.start方法启动BlockGenerator。BlockGenerator.start方法主要完成2件事情：

​		第一是启动一个数据块生成定时器，将当前currentBuffer缓存中的数据按照用户在SparkStreming应用程序中定义的批处理时间间隔封装成一个Block数据块，然后存放在BlockGeneraotr的blockForPushing队列中

​		第二是启动一个blockPushingThread线程，不断地将BlockForPushing队列中的数据块传递给BlockManager。



**4.数据存储**

​		作为流数据接收器调用Receiver.store方式进行数据存储，该方法有多个重载方法，如果数量很小，则攒多条数据成数据块再进行块存储，如果数据量大，则直接进行块存储。

​		这两种情况均调用pushAndReportBlock方法进行数据存储，

该方法一方面会调用ReceiverBlockHandler的storeBlock方法保存数据并根据配置进行预写日志，

另一方面会处理好的数据块元信息发送给ReceiverTrackerEndPoint终端点，ReceiverTracker再把这些信息转给ReceiverBlockTracker，由它负责管理收到数据块原信息。

![image-20191016143101620](https://tva1.sinaimg.cn/large/006y8mN6gy1g80119uwu7j31120p4n92.jpg)



### 4.3 数据处理

​	那么已经存储的数据真正处理是什么时候触发？

我们把视线转移到官方示例代码中，代码如下。

<img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g801b9x87mj30zu04u0ue.jpg" alt="image-20191016144017784" style="zoom: 67%;" />
<img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g801b8lgsvj312u0ay0wo.jpg" alt="image-20191016144033903" style="zoom: 67%;" />

​	在定时器timer中会定时的调用processEvent方法，对于接收到的GenerateJobs消息会调用JobGenerator.generateJobs方法继续处理。

在JobGenerator的generateJob方法中，主要进行了5个步骤：

1. 要去ReceiverTracker将目前已收到的数据进行一次提交，将上次批处理切分后未处理的数据切分到本地批处理中。

2. 调用DStreamGraph的generateJobs方法生成作业。

3. 获取接收到的Block信息，通过调用InputInfoTracker的getInfo方法把ReceiverTracker中接收到的数据块元数据，保存到batchTimeToInputInfos中这个HashMap中，然后作为参数传给JobSet。

4. 调用JobSheduler的submitJobSet方法提交作业。

5. 提交完作业后，发送一个DoCheckpoint消息给JobGenerator，然后调用JobGenerator的doCheckpoint进行检查点操作。

