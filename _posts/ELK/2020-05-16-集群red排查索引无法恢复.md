---
layout: post
title:  "集群red排查索引无法恢复"
categories: "ELK"
tags: "ELK"
author: "songzhx"
date:   2019-05-16 19:18:00
---

## 1. ES 集群状态介绍

**`green`**

所有的主分片和副本分片都已分配。你的集群是 100% 可用的。

**`yellow`**

所有的主分片已经分片了，但至少还有一个副本是缺失的。不会有数据丢失，所以搜索结果依然是完整的。不过，你的高可用性在某种程度上被弱化。如果 *更多的* 分片消失，你就会丢数据了。把 `yellow` 想象成一个需要及时调查的警告。

**`red`**

至少一个主分片（以及它的全部副本）都在缺失中。这意味着你在缺少数据：搜索只能返回部分数据，而分配到这个分片上的写入请求会返回一个异常。



## 2. 场景1

监测集群健康状态出现集群red情况：

```json
[root@es-coco-0003 exporter]# curl -XGET http://admin:admin@172.31.0.52:9200/_cluster/health?pr
{
  "cluster_name" : "elastic",
  "status" : "red",
  "timed_out" : false,
  "number_of_nodes" : 1,
  "number_of_data_nodes" : 1,
  "active_primary_shards" : 4,
  "active_shards" : 4,
  "relocating_shards" : 0,
  "initializing_shards" : 0,
  "unassigned_shards" : 2,
  "delayed_unassigned_shards" : 0,
  "number_of_pending_tasks" : 0,
  "number_of_in_flight_fetch" : 0,
  "task_max_waiting_in_queue_millis" : 0,
  "active_shards_percent_as_number" : 66.66666666666666
}
```



猜测是因为无法分片导致的问题：

```json
[root@es-coco-0003 exporter]# curl -XGET http://admin:admin@172.31.0.52:9200/_cluster/allocation/explain?pretty
{
  "index" : ".monitoring-kibana-6-2019.05.16",
  "shard" : 0,
  "primary" : true,
  "current_state" : "unassigned",
  "unassigned_info" : {
    "reason" : "CLUSTER_RECOVERED",
    "at" : "2019-05-16T10:21:55.682Z",
    "last_allocation_status" : "no_valid_shard_copy"
  },
  "can_allocate" : "no_valid_shard_copy",
  "allocate_explanation" : "cannot allocate because a previous copy of the primary shard existed but can no longer be found on the nodes in the cluster",
  "node_allocation_decisions" : [
    {
      "node_id" : "Psnm64KLRP-2BekzN7FYsw",
      "node_name" : "es-coco-0003-instance-default",
      "transport_address" : "172.31.0.52:9300",
      "node_attributes" : {
        "ml.machine_memory" : "8201945088",
        "xpack.installed" : "true",
        "ml.max_open_jobs" : "20",
        "ml.enabled" : "true"
      },
      "node_decision" : "no",
      "store" : {
        "found" : false
      }
    }
  ]
}
```

解释：

输出信息告诉我们主分片当前处于未指派状态(`current_state`), 因为之前分配了该分片的节点已从集群中离开(`unassigned_info`). `unassigned_info`告诉我们当前不能分配分片的原因是集群中没有该分片的可用备份数据(`can_allocate`), `allocate_explanation`给出了更详细的信息.

`explain API`告知我们那个主分片已没有任何可用的分片复制数据, 也就是说集群中任一拥有该分片可用的复制信息的节点都不存在了. 当前唯一能做的事就是等待节点恢复并重新加入集群. 在一些更极端场景, 这些节点被永久移除, 而此时只能接受数据丢失的事实, 并通过[reroute commends](https://www.elastic.co/guide/en/elasticsearch/reference/current/cluster-reroute.html)来重新分配空的主分片.

###  解决办法

导致集群变red，很可能是因为集群中有机子宕机了，其中一部分数据没有同步完成，因此将之前宕机的机子起来，和现有集群同步完成，集群也就恢复了。另外也可以找一台空的机子，与现有的机子组成集群，索引会自动平衡，如果集群没有数据丢失，也是可以将集群恢复正常。



## 3. 场景2

最近被要求在k8s平台上部署日志系统，要求实现filebeat-->kafka-->logstash-->es的数据流向，并用kibana做可视化查询，过程中出现一次es red状态，正好借此机会加深对es的了解。

查看所有索引信息，查看下是哪个索引的status是red导致了集群都red了

GET/_cluster/health?level=indices

```text
{
    "cluster_name": "ekos-es",
    "status": "red",
    "timed_out": false,
    "number_of_nodes": 3,
    "number_of_data_nodes": 1,
    "active_primary_shards": 0,
    "active_shards": 0,
    "relocating_shards": 0,
    "initializing_shards": 4,
    "unassigned_shards": 6,
    "delayed_unassigned_shards": 0,
    "number_of_pending_tasks": 0,
    "number_of_in_flight_fetch": 0,
    "task_max_waiting_in_queue_millis": 0,
    "active_shards_percent_as_number": 0,
    "indices": {
```

"filebeat-6.1.2-2019.03.21": {

```text
            "status": "red",
            "number_of_shards": 5,
            "number_of_replicas": 1,
            "active_primary_shards": 0,
            "active_shards": 0,
            "relocating_shards": 0,
            "initializing_shards": 4,
            "unassigned_shards": 6
        }
    }
}
```

看出有一个索引filebeat-6.1.2-2019.03.21有五个分片，每个分片一个副本，加上副本总共10个分片

查看分片详情

GET /_cluster/health?level=shards

```text
{
"cluster_name": "ekos-es",
"status": "red",
"timed_out": false,
"number_of_nodes": 3,
"number_of_data_nodes": 1,
"active_primary_shards": 3,
"active_shards": 3,
"relocating_shards": 0,
"initializing_shards": 2,
"unassigned_shards": 5,
"delayed_unassigned_shards": 0,
"number_of_pending_tasks": 0,
"number_of_in_flight_fetch": 0,
"task_max_waiting_in_queue_millis": 0,
"active_shards_percent_as_number": 30,
"indices": {
    "filebeat-6.1.2-2019.03.21": {
        "status": "red",
        "number_of_shards": 5,
        "number_of_replicas": 1,
        "active_primary_shards": 3,
        "active_shards": 3,
        "relocating_shards": 0,
        "initializing_shards": 2,
        "unassigned_shards": 5,
        "shards": {
            "0": {
                "status": "yellow",
                "primary_active": true,
                "active_shards": 1,
                "relocating_shards": 0,
                "initializing_shards": 0,
                "unassigned_shards": 1
            },
            "1": {
                "status": "yellow",
                "primary_active": true,
                "active_shards": 1,
                "relocating_shards": 0,
                "initializing_shards": 0,
                "unassigned_shards": 1
            },
            "2": {
                "status": "red",
                "primary_active": false,
                "active_shards": 0,
                "relocating_shards": 0,
                "initializing_shards": 1,
                "unassigned_shards": 1
            },
            "3": {
                "status": "yellow",
                "primary_active": true,
                "active_shards": 1,
                "relocating_shards": 0,
                "initializing_shards": 0,
                "unassigned_shards": 1
            },
            "4": {
                "status": "red",
                "primary_active": false,
                "active_shards": 0,
                "relocating_shards": 0,
                "initializing_shards": 1,
                "unassigned_shards": 1
            }
        }
    }
}
}
```



查看切片未分配原因

GET /_cluster/allocation/explain?pretty

```text
{
    "index": "filebeat-6.1.2-2019.03.21",
    "shard": 1,
    "primary": false,
    "current_state": "unassigned",
    "unassigned_info": {
        "reason": "CLUSTER_RECOVERED",
        "at": "2019-03-21T09:11:11.440Z",
        "last_allocation_status": "no_attempt"
    },
    "can_allocate": "no",
    "allocate_explanation": "cannot allocate because allocation is not permitted to any of the nodes",
    "node_allocation_decisions": [
        {
            "node_id": "XRyLkP6oQ9e3ktL4C0EC3Q",
            "node_name": "es-data2-9b7d97577-tcnp2",
            "transport_address": "10.233.88.149:9300",
            "node_decision": "no",
            "deciders": [
                {
                    "decider": "same_shard",
                    "decision": "NO",
                    "explanation": "the shard cannot be allocated to the same node on which a copy of the shard already exists [[filebeat-6.1.2-2019.03.21][1], node[XRyLkP6oQ9e3ktL4C0EC3Q], [P], s[STARTED], a[id=yjsvqcRKS4qi3wDWme1EeQ]]"
                },
                {
                    "decider": "throttling",
                    "decision": "THROTTLE",
                    "explanation": "reached the limit of incoming shard recoveries [2], cluster setting [cluster.routing.allocation.node_concurrent_incoming_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])"
                }
            ]
        }
    ]
}
```



这里能清除的看到原因：

(1). 节点上已有副本切片，导致主切片不能分配（因为主副分片不能在同一个节点）

(2). cluster.routing.allocation.node_concurrent_recoveries参数设置了每个最多能同时修复的分片数（默认为2），因为数据节点已有两个切片正在initialnizing,所以改切片不能恢复，状态为unassigned

### 解决方法

(1) 重新分配red分片，让它变为yellow





参考：

<https://segmentfault.com/a/1190000008956708>


